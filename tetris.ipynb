{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1bLePsLvBZHQimixTu8nfr0Mb3QruvANA",
      "authorship_tag": "ABX9TyPNUinvgDmJlocQZjLRvq0A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/epeay/tetris-ml/blob/main/tetris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def auto_pip(libraries):\n",
        "    \"\"\" Invokes pip if needed. Saves time if not. \"\"\"\n",
        "    import importlib\n",
        "    try:\n",
        "        for library in libraries:\n",
        "            importlib.import_module(library)\n",
        "    except ImportError:\n",
        "        !pip install {\" \".join(libraries)}\n",
        "# avoids invoking pip unless we need it\n",
        "auto_pip([\"gymnasium\"])\n",
        "\n",
        "import gymnasium as gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "import pdb\n",
        "\n",
        "import tetrislib\n",
        "\n",
        "import sys\n",
        "\n",
        "print(sys.path)\n",
        "\n",
        "sys.exit()\n",
        "\n",
        "\"\"\"\n",
        "Episode = One tetris game\n",
        "\"\"\"\n",
        "\n",
        "class ActionFeedback:\n",
        "    def __init__(self, valid_action=False):\n",
        "        self.valid_action = valid_action\n",
        "\n",
        "\n",
        "\n",
        "class TetrominoPiece:\n",
        "\n",
        "    BLOCK = '▆'\n",
        "\n",
        "    def __init__(self, shape:int, patterns):\n",
        "        self.shape:int = shape\n",
        "        self.pattern_list = patterns\n",
        "        self.pattern = patterns[0]\n",
        "        self.rot = 0\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return f\"TetrominoPiece(shape={Tetrominos.shape_name(self.shape)}, rot={self.rot*90}, pattern= {self.printable_pattern(oneline=True)})\"\n",
        "\n",
        "    def printable_pattern(self, oneline=False):\n",
        "        ret = []\n",
        "        pattern = self.get_pattern()\n",
        "        for i, row in enumerate(pattern):\n",
        "            row_str = \" \".join([str(c) for c in row])\n",
        "            ret.append(row_str)\n",
        "\n",
        "            if not oneline:\n",
        "                ret.append(\"\\n\")\n",
        "            else:\n",
        "                if i < len(pattern)-1:\n",
        "                    ret.append(\" / \",)\n",
        "        ret = \"\".join(ret).replace('1', TetrominoPiece.BLOCK).replace('0', '_')\n",
        "        return \"\".join(ret)\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            \"shape\": self.shape,\n",
        "            \"pattern\": self.pattern\n",
        "        }\n",
        "\n",
        "    def get_pattern(self):\n",
        "        return self.pattern\n",
        "\n",
        "    def rotate(self):\n",
        "        \"\"\"Rotates IN PLACE, and returns the new pattern\"\"\"\n",
        "        self.rot = (self.rot + 1) % 4\n",
        "        self.pattern = self.pattern_list[self.rot]\n",
        "        return self.pattern\n",
        "\n",
        "    def get_height(self):\n",
        "        return len(self.get_pattern())\n",
        "\n",
        "    def get_width(self):\n",
        "        return max([len(x) for x in self.get_pattern()])\n",
        "\n",
        "    def get_bottom_offsets(self):\n",
        "        \"\"\"\n",
        "        For each column in the shape, returns the gap between the bottom of\n",
        "        the shape (across all columns) and the bottom of the shape in that\n",
        "        column.\n",
        "\n",
        "        Returned values in the list would expect to contain at least one 0, and\n",
        "        no values higher than the height of the shape.\n",
        "\n",
        "        For example, an S piece:\n",
        "        _ X X\n",
        "        X X _\n",
        "\n",
        "        Would have offsets [0, 0, 1] in this current rotation. This method is\n",
        "        used in determining if a piece will fit at a certain position\n",
        "        in the board.\n",
        "        \"\"\"\n",
        "        pattern = self.get_pattern()\n",
        "        # pdb.set_trace()\n",
        "        ret = [len(pattern)+1 for x in range(len(pattern[0]))]\n",
        "        # Iterates rows from top, down\n",
        "        for ri in range(len(pattern)):\n",
        "            # Given a T shape:\n",
        "            # X X X\n",
        "            # _ X _\n",
        "            # Start with row [X X X] (ri=0, offset=1)\n",
        "            row = pattern[ri]\n",
        "            # print(f\"Testing row {row} at index {ri}\")\n",
        "            for ci, col in enumerate(row):\n",
        "                if col == 1:\n",
        "                    offset = len(pattern) - ri - 1\n",
        "                    ret[ci] = offset\n",
        "\n",
        "            # Will return [1, 0, 1] for a T shape\n",
        "\n",
        "        if max(ret) >= len(pattern):\n",
        "          print(f\"Pattern:\")\n",
        "          print(pattern)\n",
        "          print(f\"Bottom Offsets: {ret}\")\n",
        "          print(f\"Shape: {self.shape}\")\n",
        "          raise ValueError(\"Tetromino pattern has incomplete bottom offsets\")\n",
        "\n",
        "        return ret\n",
        "\n",
        "    def get_top_offsets(self):\n",
        "        \"\"\"\n",
        "        Returns the height of the shape at each column.\n",
        "\n",
        "        For example, an S piece:\n",
        "        _ X X\n",
        "        X X _\n",
        "\n",
        "        Would have offsets [1, 2, 2] in this current rotation. This provides\n",
        "        guidance on how to update the headroom list.\n",
        "\n",
        "        Ideally we should cache this.\n",
        "        \"\"\"\n",
        "        pattern = self.get_pattern()\n",
        "        ret = [0 for x in len(pattern[0])]\n",
        "        for ri, row in enumerate(range(pattern, )):\n",
        "            for col in pattern[row]:\n",
        "                if pattern[row][col] == 1:\n",
        "                    ret[col] = max(ret[col], row)\n",
        "        return ret\n",
        "\n",
        "\n",
        "class Tetrominos:\n",
        "    O = 1\n",
        "    I = 2\n",
        "    S = 3\n",
        "    Z = 4\n",
        "    T = 5\n",
        "    J = 6\n",
        "    L = 7\n",
        "\n",
        "    base_patterns = {\n",
        "        # X X\n",
        "        # X X\n",
        "        O: np.array([[1, 1], [1, 1]]),\n",
        "\n",
        "        # X X X X\n",
        "        I: np.array([[1, 1, 1, 1]]),\n",
        "\n",
        "        # _ X X\n",
        "        # X X _\n",
        "        S: np.array([[0, 1, 1], [1, 1, 0]]),\n",
        "        Z: np.array([[1, 1, 0], [0, 1, 1]]),\n",
        "        T: np.array([[1, 1, 1], [0, 1, 0]]),\n",
        "        J: np.array([[1, 0, 0], [1, 1, 1]]),\n",
        "        L: np.array([[0, 0, 1], [1, 1, 1]])\n",
        "    }\n",
        "\n",
        "    # Stores patterns for each tetromino, at each rotation\n",
        "    cache = {}\n",
        "\n",
        "    def num_tetrominos():\n",
        "        return len(Tetrominos.base_patterns.keys())\n",
        "\n",
        "    @staticmethod\n",
        "    def shape_name(shape):\n",
        "        if shape == Tetrominos.O:\n",
        "            return \"O\"\n",
        "        elif shape == Tetrominos.I:\n",
        "            return \"I\"\n",
        "        elif shape == Tetrominos.S:\n",
        "            return \"S\"\n",
        "        elif shape == Tetrominos.Z:\n",
        "            return \"Z\"\n",
        "        elif shape == Tetrominos.T:\n",
        "            return \"T\"\n",
        "        elif shape == Tetrominos.J:\n",
        "            return \"J\"\n",
        "        elif shape == Tetrominos.L:\n",
        "            return \"L\"\n",
        "        else:\n",
        "            raise ValueError(\"Invalid shape\")\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def make(shape):\n",
        "        \"\"\"\n",
        "        shape:\n",
        "        \"\"\"\n",
        "        if not Tetrominos.cache:\n",
        "            for shape, pattern in Tetrominos.base_patterns.items():\n",
        "                Tetrominos.cache[shape] = [\n",
        "                    pattern,\n",
        "                    np.rot90(pattern),\n",
        "                    np.rot90(pattern, 2),\n",
        "                    np.rot90(pattern, 3)\n",
        "                ]\n",
        "\n",
        "\n",
        "        if shape not in Tetrominos.base_patterns.keys():\n",
        "            raise ValueError(\"Invalid shape\")\n",
        "\n",
        "        return TetrominoPiece(shape, Tetrominos.cache[shape])\n",
        "\n",
        "class TetrisBoard:\n",
        "\n",
        "    BLOCK = '▆'\n",
        "\n",
        "    def __init__(self, height, width):\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.board = np.zeros((self.height, self.width), dtype=int)\n",
        "        self.headroom = [self.height for _ in range(self.width)]\n",
        "        self.piece = None\n",
        "\n",
        "    def remove_tetris(self):\n",
        "        to_delete = []\n",
        "        for r, row in enumerate(self.board):\n",
        "            if sum(row) == self.width:\n",
        "                to_delete.append(r)\n",
        "\n",
        "        if to_delete:\n",
        "          self.board = np.delete(self.board, to_delete, axis=0)\n",
        "          self.board.resize((self.height, self.width))\n",
        "          # pdb.set_trace()\n",
        "\n",
        "        return len(to_delete)\n",
        "\n",
        "    def place_piece(self, piece:TetrominoPiece, logical_coords):\n",
        "        \"\"\"\n",
        "        Places a piece at the specified column. Dynamically calculates correct\n",
        "        height for the piece.\n",
        "\n",
        "        piece: a TetrominoPiece object\n",
        "        logical_coords: The logical row and column for the bottom left\n",
        "            of the piece's pattern\n",
        "        \"\"\"\n",
        "        pattern = piece.get_pattern()\n",
        "        bottom_offsets = np.array(piece.get_bottom_offsets())\n",
        "        # TODO don't calculate all bottoms because we don't need them all\n",
        "\n",
        "        lrow = logical_coords[0]\n",
        "        lcol = logical_coords[1]\n",
        "\n",
        "        p_height = piece.get_height()\n",
        "\n",
        "        for r in range(p_height):\n",
        "            pattern_row = pattern[len(pattern)-1-r]\n",
        "            board_row = self.board[lrow-1+r]\n",
        "\n",
        "            for i, c in enumerate(pattern_row):\n",
        "                # Iff c is 1, push it to the board\n",
        "                board_row[lcol-1+i] |= c\n",
        "\n",
        "\n",
        "    def find_logical_BL_placement(self, piece:TetrominoPiece, col):\n",
        "        \"\"\"\n",
        "        Returns the logical row and column of the bottom left corner of the\n",
        "        pattern, such that when placed, the piece will sit flush against existing\n",
        "        tower parts, and not exceed the max board height.\n",
        "\n",
        "        Given:\n",
        "        BOARD       PIECE\n",
        "        5 _ _ _ _\n",
        "        4 _ _ _ X\n",
        "        3 _ _ X X   X X X X\n",
        "        2 _ X X _\n",
        "        1 X X X X\n",
        "\n",
        "        Returns (5, 1)\n",
        "\n",
        "        Given:\n",
        "        BOARD       PIECE    COL\n",
        "        5 _ _ _ _\n",
        "        4 _ _ _ X\n",
        "        3 _ _ X X   X X X    1 (lcol 2)\n",
        "        2 _ X X _     X\n",
        "        1 X X X X\n",
        "\n",
        "        Returns (3, 1)\n",
        "\n",
        "        piece: a TetrominoPiece object\n",
        "        col: zero-index column to place the 0th column of the piece.\n",
        "        \"\"\"\n",
        "        pattern = piece.get_pattern()\n",
        "        bottom_offsets = np.array(piece.get_bottom_offsets())\n",
        "        # TODO don't calculate all bottoms because we don't need them all\n",
        "        board_heights = np.array(self.get_tops()[col:col+piece.get_width()])\n",
        "\n",
        "        # Given:\n",
        "        # BOARD       PIECE\n",
        "        # 5 _ _ _ _\n",
        "        # 4 _ _ _ X\n",
        "        # 3 _ _ X X   X X X X\n",
        "        # 2 _ X X _\n",
        "        # 1 X X X X\n",
        "        # Tops -> [1,2,3,4]\n",
        "        #\n",
        "        # The sideways I has bottom offsets [0,0,0,0]\n",
        "        # Start at min(board_tops)+1 and try to place the piece.\n",
        "        #\n",
        "        # If placing on row 2, the piece heights would be [2,2,2,2]\n",
        "        # Board heights are [1,2,3,4], so this\n",
        "        # doesn't clear the board for all columns. Try placing on row 3.\n",
        "        # [3,3,3,3] > [1,2,3,4] ? False\n",
        "        # Try row 4... False. Try row 5...\n",
        "        # [5,5,5,5] > [1,2,3,4] ? True\n",
        "        # So we place the piece on row 5 (index 4)\n",
        "        #\n",
        "        # 5 X X X X\n",
        "        # 4 _ _ _ X\n",
        "        # 3 _ _ X X\n",
        "        # 2 _ X X _\n",
        "        # 1 X X X X\n",
        "        # (yes, this is a horrible move)\n",
        "\n",
        "        p_height = piece.get_height()\n",
        "        p_width = piece.get_width()\n",
        "        can_place = False\n",
        "\n",
        "        # TODO Pick better min test height\n",
        "        # If there's a very narrow, tall tower, and you're placing a flat I\n",
        "        # just to the left of it, you'll likely test placement for each level of\n",
        "        # the tower until the piece clears it.\n",
        "        for place_row in range(min(board_heights)+1, max(board_heights)+2):\n",
        "            # In the example, place_row would be 2...3...4...5\n",
        "\n",
        "            # Is [2,2,2,2] > [1,2,3,4] ?\n",
        "            # Does this placement not interfere with existing board pieces?\n",
        "            # print(f\"Trying placement at row {place_row}\")\n",
        "            # print(f\"{(bottom_offsets + place_row)} > {board_heights}\")\n",
        "\n",
        "\n",
        "\n",
        "            bottom_clears_board = all((bottom_offsets + place_row) > board_heights)\n",
        "\n",
        "            if not bottom_clears_board:\n",
        "                continue\n",
        "\n",
        "            # Check the final height\n",
        "            if place_row-1 + p_height > self.height:\n",
        "                raise ValueError(f\"Requested placement at col {col+1} would require rows {place_row}-{place_row-1 + p_height}. Piece {piece}\")\n",
        "\n",
        "            can_place = True\n",
        "            break\n",
        "\n",
        "        if not can_place:\n",
        "            # pdb.set_trace()\n",
        "            raise ValueError(f\"Piece failed to be placed at lcolumn {col+1}\")\n",
        "\n",
        "        return (place_row, col+1)\n",
        "\n",
        "    @staticmethod\n",
        "    def render_state(board, pattern, bl_coords, color=True):\n",
        "        board = board.copy()\n",
        "\n",
        "        # Highlight tiles where the last piece was played\n",
        "        lrow, lcol = bl_coords\n",
        "\n",
        "        p_height = len(pattern)\n",
        "        output = False\n",
        "\n",
        "        for r in range(p_height):\n",
        "            pattern_row = pattern[len(pattern)-1-r]\n",
        "            board_row = board[lrow-1+r]\n",
        "\n",
        "            for i, c in enumerate(pattern_row):\n",
        "                # Iff c is 1, push it to the board\n",
        "                if c == 1:\n",
        "                    board_row[lcol-1+i] = 2\n",
        "\n",
        "\n",
        "        for i, row in enumerate(reversed(board)):\n",
        "            if sum(row) == 0 and not output:\n",
        "                continue\n",
        "            else:\n",
        "                output = True\n",
        "\n",
        "            for cell in row:\n",
        "                if cell == 2:\n",
        "                    print(f\"\\033[36m{TetrisBoard.BLOCK}\\033[0m\", end=' ')\n",
        "                elif cell == 1:\n",
        "                    print(TetrisBoard.BLOCK, end=' ')\n",
        "                else:\n",
        "                    print('_', end=' ')\n",
        "            print()\n",
        "\n",
        "\n",
        "    def render(self):\n",
        "        output = False\n",
        "        for i, row in enumerate(reversed(self.board)):\n",
        "            if sum(row) == 0 and not output:\n",
        "                continue\n",
        "            else:\n",
        "                output = True\n",
        "\n",
        "            for cell in row:\n",
        "                if cell == 1:\n",
        "                    print(TetrisBoard.BLOCK, end=' ')\n",
        "                else:\n",
        "                    print('_', end=' ')\n",
        "            print()\n",
        "\n",
        "        if not output:\n",
        "            print(\"<<EMPTY BOARD>>\")\n",
        "\n",
        "\n",
        "\n",
        "    def get_tops(self):\n",
        "        \"\"\"\n",
        "        Gets the height of each column on the board.\n",
        "        This is gonna be inefficient for now.\n",
        "\n",
        "        A board with only an I at the left side would return [4, 0, 0, ...]\n",
        "        \"\"\"\n",
        "        tops = [0 for _ in range(self.width)]\n",
        "        for r, row in enumerate(self.board):\n",
        "            if sum(row) == 0:\n",
        "                break\n",
        "\n",
        "            for col, val in enumerate(row):\n",
        "                if val == 1:\n",
        "                    tops[col] = r+1\n",
        "\n",
        "        return tops\n",
        "\n",
        "\n",
        "\n",
        "class TetrisGameRecord:\n",
        "    def __init__(self):\n",
        "        self.moves = 0\n",
        "        self.lines_cleared = 0\n",
        "        self.cleared_by_size = {\n",
        "            1: 0,\n",
        "            2: 0,\n",
        "            3: 0,\n",
        "            4: 0\n",
        "        }\n",
        "        self.boards = []\n",
        "        self.pieces = []\n",
        "        self.placements = []  # Logical coords of BL corner of piece pattern\n",
        "        self.rewards = []\n",
        "        self.outcome = []\n",
        "        self.success = []\n",
        "        self.cumulative_reward = 0\n",
        "\n",
        "class TetrisEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(TetrisEnv, self).__init__()\n",
        "        self.board_height = 20\n",
        "        self.board_width = 10\n",
        "        self.board = TetrisBoard(self.board_height, self.board_width)\n",
        "        self.current_piece = None\n",
        "        self.pieces = Tetrominos()\n",
        "        self.reward_history = deque(maxlen=10)\n",
        "        self.record = TetrisGameRecord()\n",
        "\n",
        "        # Action space: tuple (column, rotation)\n",
        "        # TODO Limit action width properly\n",
        "        self.action_space = spaces.MultiDiscrete([self.board_width, 4])\n",
        "\n",
        "        # Observation space: the board state\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0,\n",
        "            high=1,\n",
        "            shape=(self.board_height * self.board_width + Tetrominos.num_tetrominos(),),\n",
        "            dtype=int\n",
        "            )\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.board.reset()\n",
        "        self.current_piece = self._get_random_piece()\n",
        "        self.record = TetrisGameRecord()\n",
        "        return self._get_board_state()\n",
        "\n",
        "    def step(self, action):\n",
        "        col, rotation = action\n",
        "\n",
        "        # Rotate the piece to the desired rotation\n",
        "        for _ in range(rotation):\n",
        "            self.current_piece.rotate() # Rotates IN PLACE\n",
        "\n",
        "        if not self._is_valid_action(self.current_piece, col+1):\n",
        "            # We may resolve this with a \"redo\" instead of stopping the episode\n",
        "            # in the future.\n",
        "            # print(\"Invalid Action\")\n",
        "            # self.board.render()\n",
        "            # print(f\"Action Column: {col+1} (1-{self.board_width})\")\n",
        "            # print(f\"Piece: {self.current_piece}\")\n",
        "            done = False\n",
        "            # print(\">>> REDO\")\n",
        "            reward = self._calculate_reward() * 0.5\n",
        "\n",
        "            self.record.moves += 1\n",
        "            self.record.boards.append(self.board.board.copy())\n",
        "            self.record.pieces.append(self.current_piece.to_dict())\n",
        "            self.record.rewards.append(reward)\n",
        "            self.record.outcome.append(\"REDO\")\n",
        "            self.record.placements.append(None)\n",
        "            self.record.success.append(False)\n",
        "            self.record.cumulative_reward += reward\n",
        "\n",
        "            return self._get_board_state(), reward, done, {}\n",
        "\n",
        "\n",
        "        try:\n",
        "            # Find where the piece would sit on the board\n",
        "            lcoords = self.board.find_logical_BL_placement(self.current_piece, col)\n",
        "        except ValueError as e:\n",
        "            # print(f\"Exception: {e}\")\n",
        "            done = True\n",
        "            # TODO Account for a fatal placement\n",
        "            # self.board.render()\n",
        "            # print(f\"Action Column: {col+1} (1-{self.board_width})\")\n",
        "            # print(f\"Piece: {self.current_piece}\")\n",
        "            reward = self._calculate_reward() * 0.5\n",
        "\n",
        "            self.record.moves += 1\n",
        "            self.record.boards.append(self.board.board.copy())\n",
        "            self.record.pieces.append(self.current_piece.to_dict())\n",
        "            self.record.rewards.append(reward)\n",
        "            self.record.outcome.append(\"OVERFLOW\")\n",
        "            self.record.placements.append(None)\n",
        "            self.record.success.append(False)\n",
        "            self.record.cumulative_reward += reward\n",
        "\n",
        "            return self._get_board_state(), reward, done, {}\n",
        "\n",
        "\n",
        "        self.board.place_piece(self.current_piece, lcoords)\n",
        "        reward = self._calculate_reward()\n",
        "        self.reward_history.append(reward)\n",
        "        done = self._is_done()\n",
        "\n",
        "        self.record.moves += 1\n",
        "        self.record.boards.append(self.board.board.copy())\n",
        "        self.record.pieces.append(self.current_piece.to_dict())\n",
        "        self.record.rewards.append(reward)\n",
        "        self.record.outcome.append(None)\n",
        "        self.record.placements.append(lcoords)\n",
        "        self.record.success.append(True)\n",
        "        self.record.cumulative_reward += reward\n",
        "\n",
        "\n",
        "        # Huzzah!\n",
        "        lines_gone = self.board.remove_tetris()\n",
        "\n",
        "        if lines_gone > 0:\n",
        "            self.record.lines_cleared += 1\n",
        "            self.record.cleared_by_size[lines_gone] += 1\n",
        "\n",
        "\n",
        "        # Prep for next move\n",
        "        self.current_piece = self._get_random_piece()\n",
        "        next_state = self._get_board_state()\n",
        "        return next_state, reward, done, {}\n",
        "\n",
        "    def render(self):\n",
        "        self.board.render()\n",
        "\n",
        "    def _get_random_piece(self):\n",
        "        return self.pieces.make(np.random.randint(1, 8))\n",
        "\n",
        "    def _is_valid_action(self, piece, lcol):\n",
        "        piece = self.current_piece\n",
        "\n",
        "        if lcol < 1 or lcol > self.board_width:\n",
        "            # print(\"col out of range\")\n",
        "            return False\n",
        "\n",
        "        # An O on col 1 would take up cols 1-2\n",
        "        if lcol + piece.get_width() -1 > self.board_width:\n",
        "            # print(\"col + width out of range\")\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def _calculate_reward(self):\n",
        "\n",
        "        # Evaluate line pack\n",
        "        # Packed lines produces a higher score\n",
        "        # Big narrow tower would produce a low score\n",
        "        active_lines = 0\n",
        "        board_tiles = 0\n",
        "        lines_cleared = 0\n",
        "        for row in self.board.board:\n",
        "            row_sum = sum(row)\n",
        "            board_tiles += row_sum\n",
        "            if row_sum == 0:\n",
        "                continue\n",
        "\n",
        "            active_lines += 1\n",
        "            if row_sum == self.board.width:\n",
        "                lines_cleared += 1\n",
        "\n",
        "        if active_lines == 0:\n",
        "            return 0\n",
        "\n",
        "        # Simulating an extra 5 packed tiles per line cleared\n",
        "        line_score = (board_tiles+(5*lines_cleared)) / float(self.board_width * active_lines)\n",
        "        reward = line_score  # That's all for now\n",
        "        return reward\n",
        "\n",
        "    def _is_done(self):\n",
        "        return False\n",
        "\n",
        "    def _get_board_state(self):\n",
        "        # Get the current board state\n",
        "        board_state = self.board.board.flatten()\n",
        "\n",
        "        # Create a one-hot encoding for the current piece\n",
        "        piece_one_hot = np.zeros(Tetrominos.num_tetrominos())\n",
        "        piece_one_hot[self.current_piece.shape - 1] = 1\n",
        "\n",
        "        # Concatenate the board state and the one-hot encoding\n",
        "        return np.concatenate([board_state, piece_one_hot])\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "  # Example usage\n",
        "  env = TetrisEnv()\n",
        "  state = env.reset()\n",
        "\n",
        "  done = False\n",
        "  loop_limit = 10\n",
        "  loop = 0\n",
        "  while not done and loop < loop_limit:\n",
        "      action = env.action_space.sample()  # Random action for demonstration\n",
        "      next_state, reward, done, _ = env.step(action)\n",
        "      env.board.render()\n",
        "      print(f\"Reward: {reward}, Done: {done}\")\n",
        "      loop += 1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6yLLSvNjgz1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "adb8f06a-6a83-4abf-c100-0908ae753ff1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content', '/env/python', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.10/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim):\n",
        "        super(DQN, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, action_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "import random\n",
        "from collections import deque\n",
        "\n",
        "class DQNAgent:\n",
        "    def __init__(self, state_dim, action_dim, learning_rate=0.001, discount_factor=0.99, exploration_rate=1.0, exploration_decay=0.995, min_exploration_rate=0.01, replay_buffer_size=10000, batch_size=64):\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim[0] * action_dim[1]  # Total number of actions\n",
        "        self.discount_factor = discount_factor\n",
        "        self.exploration_rate = exploration_rate\n",
        "        self.exploration_decay = exploration_decay\n",
        "        self.min_exploration_rate = min_exploration_rate\n",
        "        self.replay_buffer = deque(maxlen=replay_buffer_size)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.model = DQN(state_dim, self.action_dim)\n",
        "        self.target_model = DQN(state_dim, self.action_dim)\n",
        "        self.update_target_model()\n",
        "\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "        self.loss_fn = nn.MSELoss()\n",
        "        self.game_records = []\n",
        "\n",
        "    def update_target_model(self):\n",
        "        self.target_model.load_state_dict(self.model.state_dict())\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.replay_buffer.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def guess(self, state):\n",
        "        return (random.randint(0, self.action_dim // 4 - 1), random.randint(0, 4 - 1))\n",
        "\n",
        "    def predict(self, state):\n",
        "        state = torch.FloatTensor(state).unsqueeze(0)\n",
        "        q_values = self.model(state)\n",
        "        action_index = torch.argmax(q_values).item()\n",
        "        return (action_index // 4, action_index % 4)\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if random.uniform(0, 1) < self.exploration_rate:\n",
        "            return self.guess(state)\n",
        "        else:\n",
        "            return self.predict(state)\n",
        "\n",
        "    def evaluate(self, env, num_episodes=10):\n",
        "        total_rewards = []\n",
        "        for _ in range(num_episodes):\n",
        "\n",
        "            self.game_records.append(env.record)\n",
        "\n",
        "            state = env.reset()\n",
        "            total_reward = 0\n",
        "            done = False\n",
        "            while not done:\n",
        "                action = self.predict(state)  # Always use the learned policy\n",
        "                next_state, reward, done, _ = env.step(action)\n",
        "                state = next_state\n",
        "                total_reward += reward\n",
        "            total_rewards.append(total_reward)\n",
        "        return total_rewards\n",
        "\n",
        "\n",
        "    def train(self, env, num_episodes=10):\n",
        "        total_rewards = []\n",
        "        target_update_interval = 10\n",
        "\n",
        "        for episode in range(num_episodes):\n",
        "            if env.record.moves > 0:\n",
        "                self.game_records.append(env.record)\n",
        "            state = env.reset().flatten()  # Flatten the state to fit the input of the network\n",
        "            step_count = 0\n",
        "            total_reward = 0\n",
        "            done = False\n",
        "\n",
        "            while not done:\n",
        "                action = agent.choose_action(state)\n",
        "                next_state, reward, done, _ = env.step(action)\n",
        "                step_count += 1\n",
        "                next_state = next_state.flatten()\n",
        "\n",
        "                self.remember(state, action, reward, next_state, done)\n",
        "                self.replay()\n",
        "                state = next_state\n",
        "                total_reward += reward\n",
        "\n",
        "            self.decay_exploration_rate()\n",
        "            total_rewards.append(total_reward)\n",
        "\n",
        "            if episode % target_update_interval == 0:\n",
        "                agent.update_target_model()\n",
        "\n",
        "        return total_rewards\n",
        "\n",
        "\n",
        "    def replay(self):\n",
        "        if len(self.replay_buffer) < self.batch_size:\n",
        "            return\n",
        "\n",
        "        # print(\">>>> REPLAY\")\n",
        "        batch = random.sample(self.replay_buffer, self.batch_size)\n",
        "        states, actions, rewards, next_states, dones = zip(*batch)\n",
        "\n",
        "        states = torch.FloatTensor(states)\n",
        "        actions = torch.LongTensor([a[0] * 4 + a[1] for a in actions])\n",
        "        rewards = torch.FloatTensor(rewards)\n",
        "        next_states = torch.FloatTensor(next_states)\n",
        "        dones = torch.FloatTensor(dones)\n",
        "\n",
        "        # Calculate current Q values\n",
        "        q_values = self.model(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
        "\n",
        "        # Calculate next Q values using the target model\n",
        "        next_q_values = self.target_model(next_states).max(1)[0]\n",
        "        target_q_values = rewards + self.discount_factor * next_q_values * (1 - dones)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = self.loss_fn(q_values, target_q_values)\n",
        "\n",
        "        # Perform the optimization step\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "    def decay_exploration_rate(self):\n",
        "        self.exploration_rate = max(self.min_exploration_rate, self.exploration_rate * self.exploration_decay)\n"
      ],
      "metadata": {
        "id": "-5CwQMy0yPYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Tetris environment\n",
        "env = TetrisEnv()\n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.nvec\n",
        "\n",
        "agent = DQNAgent(state_dim, action_dim)\n",
        "\n",
        "num_episodes = 10\n",
        "target_update_interval = 10\n",
        "\n",
        "training_tracker = []\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-4Y3mgHvlrH",
        "outputId": "9e74bcbb-d86d-4b4d-9d0b-b7e1fb6eec1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.738097784568373, 8.831328671328672, 9.555963664818155, 10.728552830038899, 5.8938041112654105, 9.188277944106117, 8.33229436713957, 5.171808018263126, 6.651104901290662, 4.682355977355977, 4.31929292929293, 11.149641947319967, 8.267410951621478, 8.228891346012091, 6.6988095238095235, 11.132971472971475, 10.719028560019273, 6.155971593765714, 10.388941497099395, 6.3597186147186155, 3.5374560080442436, 7.147582757799477, 15.643380055616898, 7.411849816849819, 4.4664127702363, 2.397044329939067, 8.156083524318822, 10.245952380952383, 10.789433811802233, 6.909817324058809, 8.556541996015682, 7.633655367680137, 7.739112554112555, 6.357315462315462, 15.589264069264066, 8.30405760905761, 2.914761904761905, 9.814126984126986, 8.467515262515263, 9.82294144108386, 4.999796380090497, 6.8310901645653965, 5.256492210919456, 12.230522875816996, 6.908549314462627, 14.784156431803488, 8.315559922533609, 8.301485152274628, 6.601884226884226, 6.837871017871018, 8.111375944317121, 8.862429967693128, 9.01183940242764, 10.350358605962324, 9.001862421204526, 9.312837995337999, 7.693739316239316, 8.294559884559886, 7.108506330271038, 10.504603174603178, 11.254935064935067, 10.180164835164838, 7.80978445531077, 7.103040293040293, 12.991520646536127, 10.929351432880848, 7.982059069241733, 9.398933608531133, 9.10684407096172, 7.872595213524007, 15.014723202494103, 7.524029190623619, 10.260476833108415, 10.673153594771243, 8.073226381461678, 10.173783724015923, 8.173055555555557, 12.24285767895675, 4.387295599137703, 12.748520074696545, 8.252577030812326, 7.120375939849624, 10.06885482938115, 11.727132867132868, 2.125793650793651, 6.943070912575557, 9.421464646464646, 8.604693084693086, 5.415637578795473, 10.402034900084434, 13.34597953216374, 9.922464494569759, 8.042106782106782, 9.353719788982952, 10.1522010909627, 6.805756950308032, 8.878261831048212, 6.332597268572502, 8.359086754318955, 10.231388888888887]\n",
            "Rewards avg/min/max: 8.538236422246486/2.125793650793651/15.643380055616898\n",
            "[6.213209013209014, 11.475238095238092, 10.190163170163173, 8.374126984126985, 8.679082321187586, 11.800597706387178, 14.550723188060648, 3.105413533834586, 10.39515067320021, 11.46531861327527, 9.028203463203466, 12.109241854636592, 6.686278021943657, 5.445882352941177, 7.065555555555556, 8.03891774891775, 6.887412649270235, 10.710723443223445, 11.614210203281411, 12.5034649122807, 11.342408963585436, 11.42667799348914, 11.498394997675183, 10.239779289338117, 9.346825396825396, 10.30366669879828, 12.062417027417027, 8.46372180451128, 9.841666666666665, 7.738040707142875, 6.371056166056166, 11.73694943944944, 7.833039901275198, 4.034993894993893, 14.465214780919117, 11.441228070175441, 5.1445970695970695, 5.8162913522665844, 10.028931623931628, 10.675577740972482, 12.673506503816103, 8.243640429058386, 5.834477861319965, 9.816048951048948, 11.119220713926598, 15.25800693286762, 7.387601043607238, 9.922058823529412, 9.178521086756382, 8.44131681184313, 10.324734563681938, 7.850696594427245, 9.70733352990319, 10.515984479916371, 9.925500303789777, 8.282300068352702, 12.546825396825396, 9.862564102564104, 8.0611325928973, 9.629292490275464, 6.947705225630923, 8.603333333333333, 8.856831501831502, 12.411291917576756, 8.396470342522976, 8.239764679764681, 11.564369546861807, 9.849598244892364, 6.620230880230882, 6.072187028657615, 10.424100316608055, 5.4083367509683296, 8.187110110391846, 10.79282958527541, 7.224254196096303, 11.440145344851231, 8.085689865689867, 10.73012151591099, 10.595983265100914, 6.835183792815371, 9.967539682539682, 9.687077922077924, 10.10336257309942, 8.576217410040943, 6.7192369687416145, 7.20415412760614, 13.102019360068883, 9.190180995475117, 14.623807028884427, 16.885828901061096, 4.448846626369845, 11.482175631386163, 9.165641554867564, 12.284558774558775, 4.898478714268188, 7.300750197514905, 9.095284780578895, 11.36429707547355, 10.680041592394534, 13.177603322030569]\n",
            "Rewards avg/min/max: 9.4797379705348/3.105413533834586/16.885828901061096\n",
            "[10.58715635241951, 4.975584284996049, 8.025079365079366, 9.658914521151361, 13.759830023777388, 13.08562525709584, 10.333881037263387, 10.90853695324284, 8.83320102669948, 6.443982128982128, 20.573866192287248, 12.940079365079365, 9.726520088099036, 11.426351172047772, 8.072618606883314, 7.7404983045849916, 9.484470981375008, 9.763650793650799, 10.059786896969559, 11.101150983519398, 8.644826080352399, 12.101352579309243, 9.663174603174603, 14.591229309905783, 8.511626984126984, 8.152041262830737, 6.384619498148912, 16.397182539682536, 13.856937017231129, 8.016842105263159, 5.915917415917415, 8.242777777777778, 8.067722832722835, 16.63223942208463, 5.909109954373112, 8.995376933867647, 9.485254482359748, 10.56121572871573, 9.480464698699997, 9.430360913596209, 8.483436400201105, 11.96336447178553, 7.11484126984127, 14.815219298245614, 9.333997493734337, 18.51478107032287, 6.5235714285714295, 7.274178628389155, 11.744654566279957, 12.257358798751985, 15.966022632338412, 11.213157894736842, 13.436187036218001, 9.402619047619048, 13.706245158350418, 7.393646616541354, 16.43943906798396, 12.210952380952383, 4.55057876763759, 6.373667502088555, 8.932222222222226, 7.768318377528907, 12.659022205864316, 7.0571759166186405, 10.923301844354482, 13.81021038644878, 7.58657999894842, 12.28429308565533, 12.552885154061629, 7.891044500734906, 13.695721997300943, 4.882944862155388, 8.671712374312992, 11.548249791144528, 5.808754578754578, 17.953114157943872, 5.151112566484083, 8.506092153460573, 5.730914786967418, 9.810971735522827, 12.222543859649125, 4.9050505050505055, 9.410187009413018, 10.486112205647812, 8.918181818181818, 6.223695513293036, 5.803355696590993, 6.2644888444888425, 7.954336217617951, 12.30537895540992, 9.621856725146198, 6.963039045577746, 6.92865800865801, 4.109338944509223, 13.110289326256815, 12.064869545659022, 14.11900679729627, 10.457459207459209, 10.425988349455842, 10.341699791436639]\n",
            "Rewards avg/min/max: 10.011191550692171/4.109338944509223/20.573866192287248\n",
            "[9.952831348218348, 6.217606837606839, 3.8768016194331985, 10.60557945666304, 6.969753253282666, 11.476797385620927, 16.588946667367722, 10.824017499528336, 6.045555555555555, 9.865113764804168, 14.251455240665772, 9.630367585630744, 11.948622659590153, 9.370612002376712, 5.967732822732823, 17.372022363601307, 12.121808934099953, 12.903159274935591, 6.5845868166920765, 17.03416648710766, 7.033000071823602, 13.944911297852482, 16.626157059314956, 4.013950026581606, 18.36167651749695, 13.078383838383846, 11.725460475197313, 7.281282573635514, 11.24714285714287, 6.019368474662592, 19.917866300366292, 10.506242415994738, 27.61954444935868, 17.405947712418303, 19.892248015142744, 10.097190033908303, 15.769092338689866, 10.235687257359087, 14.498841712123449, 18.725809778456835, 19.05393162393162, 8.434559815829163, 12.046666666666669, 8.835160896894644, 13.266949593234436, 13.146601731601727, 13.796805191712307, 20.035751633986916, 18.36551444427607, 6.180683526999313, 12.579265091633518, 8.152031628502217, 13.343623832308028, 3.1947593582887697, 9.81761767472294, 11.668623481781378, 10.535760233918129, 11.70721415839063, 9.37000660158555, 18.01018303334093, 12.791607979224088, 9.624837443258489, 15.06742009624363, 12.497962553442425, 9.20427738927739, 16.584053081421512, 13.483776615541325, 8.77957459808853, 21.11166382636968, 10.266655676624717, 15.06568124685772, 9.898483085541912, 8.980041128462185, 17.711751932278247, 14.883162393162392, 12.647967914438507, 12.655810330020845, 17.136421356421344, 8.988253119429586, 16.480994794679003, 6.076825396825397, 6.817324687696207, 9.142714119385943, 19.320121240988087, 11.181280853649277, 7.207808246105459, 9.027860962566846, 18.477919799498743, 15.95065101565103, 8.193320802005013, 8.805038236617186, 16.51831373305058, 15.602674710910012, 15.456823699176637, 12.679196359196348, 10.559709880762512, 25.629281023414183, 12.663636363636373, 8.37412595660274, 10.76981571575998]\n",
            "Rewards avg/min/max: 12.374638903653105/3.1947593582887697/27.61954444935868\n",
            "[14.74063692413538, 8.398134589868336, 15.850386835386836, 8.78153766769866, 16.680939112487103, 15.961694968258437, 9.87679487179487, 13.873565062388588, 11.839298245614037, 8.023913403418048, 11.333333333333323, 15.103497156438342, 13.406233211233216, 9.633799533799538, 10.72982456140351, 7.1061050061050075, 9.197885154061623, 21.875042501358315, 12.300127014368504, 8.62280218147865, 11.112965747702589, 7.067144785039523, 27.809042448779266, 16.13400928792569, 17.114458874458876, 4.358922305764411, 10.887552447552444, 19.9725313283208, 20.043803582038905, 19.608335232019407, 26.739297385620915, 22.375236299648066, 15.270062649768517, 29.1187606837607, 11.158940620782728, 12.79096530920059, 15.879465642716431, 17.70700854700854, 10.393128749475503, 19.3717589806135, 6.931596638655463, 19.872605495639565, 14.547487227255012, 20.398014153029646, 9.320316817685239, 8.09153127917834, 23.85656722018954, 1.9020202020202024, 10.211052631578944, 6.918049401578814, 15.021339888181988, 9.418753403459277, 5.818907563025212, 7.7016532796408965, 9.220478468899516, 21.0504761904762, 21.9141916906623, 16.74150375939851, 8.040259472209936, 32.87094322344322, 15.397529787034436, 12.855946275946268, 13.512006033182512, 6.587167773746722, 13.660464155727308, 24.491865079365088, 13.993411827250833, 5.715214395167955, 8.526652236652238, 22.65540745803904, 11.353179148852522, 8.888333333333339, 17.47544919992289, 16.50228587202273, 17.487878151260507, 12.298809523809515, 35.73950186294619, 11.635457035224826, 20.385494015788147, 27.623051977262527, 15.357402514925731, 24.530238095238055, 20.594990238519657, 23.114603174603186, 11.954940786767388, 16.018515607199806, 19.446241536241548, 18.325985892332643, 27.433534214323668, 10.168727210182324, 13.07162393162393, 16.8152380952381, 19.640699006875494, 9.9612861527877, 10.348141621020876, 17.81746572313135, 25.543945792769307, 12.683192655297923, 13.531217466743774, 15.77909697114032]\n",
            "Rewards avg/min/max: 15.07018882078534/1.9020202020202024/35.73950186294619\n",
            "Training completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do/Continue training without resetting the env\n",
        "\n",
        "for i in range(5):\n",
        "    rewards = agent.train(env, 100)\n",
        "    training_tracker.append((\"TRAIN\", rewards))\n",
        "    print(rewards)\n",
        "    print(f\"Rewards avg/min/max: {np.average(rewards)}/{np.min(rewards)}/{np.max(rewards)}\")\n",
        "\n",
        "for i in range(0):\n",
        "    rewards = agent.evaluate(env, 100)\n",
        "    print(rewards)\n",
        "    training_tracker.append((\"EVALUATE\", rewards))\n",
        "    print(f\"Rewards avg/min/max: {np.average(rewards)}/{np.min(rewards)}/{np.max(rewards)}\")\n",
        "    rewards = agent.train(env, 100)\n",
        "    print(rewards)\n",
        "    training_tracker.append((\"TRAIN\", rewards))\n",
        "    print(f\"Rewards avg/min/max: {np.average(rewards)}/{np.min(rewards)}/{np.max(rewards)}\")\n",
        "\n",
        "\n",
        "print(\"Training completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uw8mpOuNAkEL",
        "outputId": "acee96a7-9c8a-431a-e9c3-adfacd3a983c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16.72458995081287, 8.751499582289055, 15.712357212790643, 8.953342670401492, 12.853992673992671, 22.26077036396699, 19.183218623481785, 10.555093606084318, 10.365026291218246, 6.326855301561184, 17.369021150847768, 14.290117271789084, 13.103591189512242, 10.994536340852134, 29.491935520619688, 7.561241830065358, 25.586553773024374, 14.159929719403392, 30.417298326028995, 27.53943381180223, 12.754666076957117, 6.8909690893901425, 15.404833003254076, 28.174920634920618, 8.336217834453128, 20.098377561550926, 18.305422551304886, 10.617656887316329, 20.34892572339941, 8.063832375055286, 13.651904761904758, 34.467282658002546, 11.841904761904766, 10.308587645584549, 11.024632414369247, 16.475946275946296, 11.783684298157972, 12.469765590446698, 43.88453449800961, 28.479028944911267, 32.85742815148385, 9.101430849851907, 11.31189865689865, 8.352054601744996, 13.718137254901952, 21.130476370035204, 39.12432900432908, 25.488947368420984, 9.622907647907644, 12.084926184926175, 25.046690420003067, 11.800411255411248, 14.621106442577013, 31.823585858585837, 18.954540366754, 13.850241629715313, 21.23023088023085, 24.005263559969404, 23.679031524031526, 15.485571504518859, 11.197019519867803, 13.750527903469063, 19.731140350877165, 3.8966666666666665, 27.830893409995536, 19.773475846478945, 8.176111111111114, 11.825301332654261, 23.806570101724883, 17.297117392411486, 17.266979307242487, 24.774836601307147, 4.036507936507936, 25.89872662425295, 5.558954203691045, 37.901297591297556, 22.90764752791071, 26.376343800678164, 7.380715514275883, 49.694743589743624, 30.814570723394226, 14.260432900432878, 19.14828320802004, 44.165814536340925, 31.196588954561083, 6.982597402597403, 31.33574263713581, 18.604302931330796, 12.061705064801036, 8.229766081871343, 13.228325046126903, 21.034786324786328, 30.88830940988836, 29.02801587301587, 5.696566113624936, 30.238289283815565, 14.741449515396887, 22.797469654528513, 27.33664642375165, 12.263839902787259]\n",
            "Rewards avg/min/max: 18.520077866500543/3.8966666666666665/49.694743589743624\n",
            "[32.759137266242554, 30.475177828707267, 14.739870129870123, 34.33230625583565, 14.828659091166818, 5.2505309276207095, 17.145710137815403, 14.750704295704299, 14.34349118717542, 5.836936005171303, 19.23182875947582, 35.66423559928203, 43.40599281007944, 15.545059976143552, 15.957392009435356, 17.738140047087427, 33.264906198033046, 20.30611233967271, 6.2197505074904464, 14.730669007634948, 24.831405340445578, 8.78391616295641, 17.22752181255274, 16.103174603174608, 30.207667925469714, 3.7079087424443458, 29.183667256376268, 33.74868967290027, 9.263188653451813, 25.044113402936933, 25.97428571428573, 42.86111961310119, 46.91846153846154, 9.048538128538132, 15.906919191919187, 49.65887641770002, 12.809759363443579, 7.142539323421679, 12.73733371891267, 37.08770817417876, 23.589880952380966, 15.221980687011639, 47.236411862990884, 32.186314270524726, 14.795337995338006, 11.545451127819554, 32.47934065934061, 20.01852941176469, 12.651815757342069, 13.83047619047619, 37.120590513717445, 46.65079021082108, 15.149126984126987, 25.499486215538848, 6.231195636149195, 58.63473673041805, 10.30271529296297, 13.465095753919277, 6.728937728937731, 9.695563016275093, 15.868571428571432, 18.516428571428545, 32.160989598636654, 21.30039682539682, 11.63668883747831, 25.555361405020918, 22.279158826209947, 20.799898989899, 22.488893651927736, 17.015765545084438, 18.155275443510707, 10.537047637604912, 17.557593582887684, 12.028661369590166, 42.03730976282054, 24.532798171900374, 15.512966127439787, 16.432399296609823, 6.949033568770412, 63.07881419234359, 7.421045260209349, 44.0606676003735, 18.786363636363657, 64.69366978051204, 16.434715197083612, 22.8924420677362, 4.554008818838541, 11.275559553965127, 25.18367699551912, 21.812612942612947, 30.818801169590625, 33.61441336441342, 25.05972339064444, 21.55882423132421, 23.057049062049014, 25.89481129981124, 20.380025062656657, 55.368833849329405, 12.652098749204011, 16.967342330871748]\n",
            "Rewards avg/min/max: 22.547379193304124/3.7079087424443458/64.69366978051204\n",
            "[17.18346856445928, 10.525583566760035, 32.92502442002447, 9.865368077055383, 11.983914460152855, 56.768888888889144, 8.048924963924964, 25.50091744512804, 18.826595918701198, 13.044523809523831, 34.42812749342173, 15.362070707070703, 143.39981203007332, 37.6060224089636, 58.64231572521076, 58.100898078529426, 31.145976800976705, 22.845047989506234, 39.77528468607408, 20.952128427128425, 53.91929745177419, 21.98537947432687, 28.991666666666596, 33.39206349206359, 9.867139506520322, 28.88481240981246, 51.82829004329031, 13.374939309056963, 61.11907907022482, 17.94864383982029, 74.80351253321852, 13.829409479409462, 32.42878510378515, 9.050970206264322, 33.150850119952196, 50.003138818525684, 10.420852130325809, 59.500497076023706, 16.97055555555553, 45.63824561403507, 23.872400018282367, 21.50448288038073, 72.07668048325937, 41.715634920635026, 25.584354797249507, 37.49157238014824, 99.23984158256553, 16.307402597402614, 37.35911749069635, 17.170249007957995, 32.047800269905565, 92.75859118006112, 42.87525681920418, 23.404047619047642, 97.91451520443712, 54.86770739064843, 27.363494142596327, 25.481904761904794, 49.97112554112532, 33.623784829721366, 27.50844655344656, 27.707044426162067, 38.22200322553264, 6.079045165360955, 42.50190476190459, 39.918287065531565, 22.877994023520298, 13.266424394319136, 12.70600212652844, 25.028938371569907, 23.49569264069259, 12.385634920634907, 29.125610371740375, 27.925346531693336, 47.49755476034089, 84.62280487314484, 20.415021181089262, 28.526024955436725, 12.48320416425678, 4.098751803751803, 64.9889377856407, 72.09747596744526, 35.76913607548271, 8.46030303030303, 8.42892002734108, 119.55297508477167, 27.198028101929, 33.72371794871786, 57.18088456435229, 18.017001081134197, 26.709277454571644, 19.058712464006625, 14.902192807192806, 9.127948717948719, 30.49042834702272, 18.918771929824572, 30.41560490764823, 5.715229606994314, 16.388888888888868, 9.975528035775719]\n",
            "Rewards avg/min/max: 33.80180685423106/4.098751803751803/143.39981203007332\n",
            "[3.2104787369493253, 56.049360902255906, 51.88102981813488, 79.12052852719972, 116.7023411469861, 147.7564607597423, 41.424669365722124, 77.12672514619888, 23.925589993082262, 10.323135137995822, 19.648933288933257, 32.14138366277695, 35.27390559732668, 23.52133470932226, 28.779196329985744, 64.9920445344128, 16.71031404268249, 61.890128205128136, 6.2813280115137715, 55.90461785032967, 44.27729437229444, 68.40354256854287, 25.919461683827056, 47.641907308377974, 79.65495405179549, 51.6380104673448, 18.918683473389347, 39.458145743145515, 159.63522247360532, 18.098714969241293, 100.2843999138122, 81.11225146198804, 22.025075187969943, 113.59520164046427, 48.53171717171718, 26.700133308384096, 29.98809523809521, 69.16827702741014, 82.39284610813974, 9.143856640435589, 50.42108285763095, 84.26936700726219, 26.024292745438252, 31.344769119769214, 26.692939903233974, 9.468972582285279, 34.6597025265757, 44.84573854422153, 28.179236874236828, 17.874713327608088, 46.81096459096448, 101.4408080808081, 51.686349206349234, 51.58281218781222, 46.26168174962308, 17.302564102564094, 83.23498925567067, 62.875518207282745, 20.09191919191919, 125.86679390784703, 30.505616313511123, 9.486601399976006, 109.67601712614803, 81.06832614495909, 22.235719199960705, 27.350444493586863, 102.1157173382183, 29.553154623154597, 82.41595662507349, 191.43239766081754, 10.854672778202183, 17.42924743986662, 76.69741705319072, 128.43793851659254, 34.165044563279864, 47.80505086245034, 97.4439146079236, 27.98645142267433, 86.11659733799041, 26.736741854636556, 25.070408260470238, 44.20306465464375, 17.56857142857143, 37.50068160597564, 34.71314234784833, 54.779796304486794, 29.245793650793622, 83.64032569597565, 91.00384615384586, 37.62414846247661, 49.790251911831106, 42.47062656641613, 86.50358585858598, 13.092474747474755, 7.439122807017544, 466.98621746674735, 74.1817543859647, 60.136946823386474, 20.71444444444441, 12.570989974937337]\n",
            "Rewards avg/min/max: 55.78935733459869/3.2104787369493253/466.98621746674735\n",
            "[43.638710350537, 21.660348715611885, 18.252979064279387, 52.23814208667145, 33.65953128742607, 33.73027834738362, 140.21854628085848, 43.78652014652019, 91.95991056071487, 52.067544351073614, 41.03250572956457, 24.583221288515457, 158.92374269005714, 18.483696741854647, 11.609434682964094, 82.02001298495149, 36.285555555555604, 26.458833849329157, 71.74731387291732, 26.662132867132808, 31.524548872180503, 64.73201938670185, 323.93448697501094, 26.29713450292396, 74.00063264221124, 47.057958130620754, 71.71251984126964, 66.72768315018303, 31.794932920536695, 127.98055234239362, 62.1862617941919, 8.213282682230053, 186.78809523809574, 256.01212510914985, 47.78014047356142, 162.19462729221237, 40.86206472062505, 41.029536794474886, 13.218209427311606, 15.946675108517185, 15.499340329433215, 48.7422646359488, 93.85498491704391, 64.47649122807, 107.6347560076663, 30.895039872408226, 4.981212500949344, 14.14890850119952, 39.80263382816003, 82.38830999066295, 26.012661064425714, 110.99217194570122, 105.12755799755826, 34.10201964701963, 34.43422852001796, 55.73701754385994, 42.200890952872285, 144.9423809523799, 50.107564102564176, 56.41966107507904, 26.477101202890694, 67.9439682539683, 37.32405067928297, 55.11960784313733, 50.502380952381195, 44.99168067226884, 175.04609857978357, 11.656904761904736, 16.81792663476873, 12.822920536635696, 4.66251012145749, 38.76392859977999, 10.853435132119344, 37.746704260651654, 14.313799846524317, 36.01325396825417, 45.48639515455306, 146.92022675466907, 67.72507936507958, 130.54327583665142, 161.505726169255, 59.52772481216768, 127.23376873126863, 23.40880952380954, 79.48237806053585, 45.93554945054945, 71.15984126984146, 63.44055555555572, 118.0821428571432, 17.791949660246875, 103.45443381180245, 125.16880099089117, 80.60694685431545, 184.03920764478133, 91.30309015374134, 69.80411764705893, 52.21628427128426, 119.38935194836063, 37.586524400951724, 126.15730769230701]\n",
            "Rewards avg/min/max: 66.80538305133972/4.66251012145749/323.93448697501094\n",
            "Training completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import sys\n",
        "\n",
        "records = agent.game_records\n",
        "\n",
        "for i, g in enumerate(records):\n",
        "    g.id = i\n",
        "\n",
        "    real_outcomes = len(list(filter(lambda x: (x is not None), g.placements)))\n",
        "    # print(f\"Game {i} placements {len(g.placements)}, REAL placements {real_outcomes} diff {real_outcomes-len(g.placements)}\")\n",
        "    g.real_moves = real_outcomes\n",
        "\n",
        "\n",
        "\n",
        "# for i in range(10):\n",
        "#     print(f\"Moves: {records[i].moves}\")\n",
        "#     print(f\"Lines cleared: {records[i].lines_cleared}\")\n",
        "#     print(f\"Cumulative reward: {records[i].cumulative_reward}\")\n",
        "#     print(\"----------------------\")\n",
        "\n",
        "\n",
        "s_games = sorted(records, key=lambda x: x.real_moves, reverse=True)\n",
        "\n",
        "show_me = s_games[0]\n",
        "\n",
        "print(f\"Moves: {show_me.moves}\")\n",
        "print(f\"Lines cleared: {show_me.lines_cleared}\")\n",
        "print(f\"Boards Length: {len(show_me.boards)}\")\n",
        "print(f\"Rewards Length: {len(show_me.rewards)}\")\n",
        "\n",
        "print(show_me.placements)\n",
        "\n",
        "print(show_me.lines_cleared)\n",
        "print(show_me.cleared_by_size)\n",
        "for i in range(show_me.moves):\n",
        "    board = show_me.boards[i]\n",
        "    piece = show_me.pieces[i]\n",
        "    placement = show_me.placements[i]\n",
        "\n",
        "    if piece and placement:\n",
        "        TetrisBoard.render_state(show_me.boards[i], show_me.pieces[i]['pattern'], show_me.placements[i])\n",
        "        print(f\"Reward: {show_me.rewards[i]}\")\n",
        "        print(\"----------------------\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtbsCEAatts4",
        "outputId": "0fa4e208-10bb-4782-94d3-854e6fafa28e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moves: 193\n",
            "Lines cleared: 2\n",
            "Boards Length: 193\n",
            "Rewards Length: 193\n",
            "[(1, 1), (3, 1), (1, 9), (1, 6), (5, 1), (3, 7), (5, 7), (1, 4), (3, 4), (5, 4), (7, 1), (8, 4), (6, 7), (9, 8), (9, 9), (7, 2), (11, 1), (12, 9), (15, 9), (15, 1), (9, 3), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, (12, 2), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, (19, 1), (8, 6), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, (9, 7), (12, 6), (15, 7), (17, 7), (9, 4), (11, 4), (14, 4), (17, 4), None, None, None, (19, 5), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
            "2\n",
            "{1: 2, 2: 0, 3: 0, 4: 0}\n",
            "\u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ _ _ _ _ _ _ _ \n",
            "\u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ _ _ _ _ _ _ _ \n",
            "Reward: 0.2\n",
            "----------------------\n",
            "\u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ _ _ _ _ _ _ _ \n",
            "\u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ _ _ _ _ _ _ _ \n",
            "▆ ▆ _ _ _ _ _ _ _ _ \n",
            "▆ ▆ _ _ _ _ _ _ _ _ \n",
            "Reward: 0.2\n",
            "----------------------\n",
            "▆ ▆ _ _ _ _ _ _ _ _ \n",
            "▆ ▆ _ _ _ _ _ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m \n",
            "▆ ▆ _ _ _ _ _ _ _ \u001b[36m▆\u001b[0m \n",
            "▆ ▆ _ _ _ _ _ _ _ \u001b[36m▆\u001b[0m \n",
            "Reward: 0.3\n",
            "----------------------\n",
            "▆ ▆ _ _ _ _ _ _ _ _ \n",
            "▆ ▆ _ _ _ _ _ _ ▆ ▆ \n",
            "▆ ▆ _ _ _ _ _ \u001b[36m▆\u001b[0m _ ▆ \n",
            "▆ ▆ _ _ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ ▆ \n",
            "Reward: 0.4\n",
            "----------------------\n",
            "\u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ _ _ _ _ _ _ _ \n",
            "\u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ _ _ _ _ _ _ _ \n",
            "▆ ▆ _ _ _ _ _ _ _ _ \n",
            "▆ ▆ _ _ _ _ _ _ ▆ ▆ \n",
            "▆ ▆ _ _ _ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ _ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.3333333333333333\n",
            "----------------------\n",
            "▆ ▆ _ _ _ _ _ _ _ _ \n",
            "▆ ▆ _ _ _ _ _ _ _ _ \n",
            "▆ ▆ _ _ _ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ \n",
            "▆ ▆ _ _ _ _ \u001b[36m▆\u001b[0m _ ▆ ▆ \n",
            "▆ ▆ _ _ _ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ _ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.4\n",
            "----------------------\n",
            "▆ ▆ _ _ _ _ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ \n",
            "▆ ▆ _ _ _ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ _ \n",
            "▆ ▆ _ _ _ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ _ _ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ _ _ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ _ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.4666666666666667\n",
            "----------------------\n",
            "▆ ▆ _ _ _ _ _ ▆ ▆ _ \n",
            "▆ ▆ _ _ _ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ _ _ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ _ \u001b[36m▆\u001b[0m _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ \u001b[36m▆\u001b[0m ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.5333333333333333\n",
            "----------------------\n",
            "▆ ▆ _ _ _ _ _ ▆ ▆ _ \n",
            "▆ ▆ _ _ \u001b[36m▆\u001b[0m _ ▆ ▆ _ _ \n",
            "▆ ▆ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ \u001b[36m▆\u001b[0m ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.6\n",
            "----------------------\n",
            "_ _ _ _ \u001b[36m▆\u001b[0m _ _ _ _ _ \n",
            "▆ ▆ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ _ ▆ ▆ _ \n",
            "▆ ▆ _ \u001b[36m▆\u001b[0m ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.5714285714285714\n",
            "----------------------\n",
            "\u001b[36m▆\u001b[0m _ _ _ _ _ _ _ _ _ \n",
            "\u001b[36m▆\u001b[0m _ _ _ _ _ _ _ _ _ \n",
            "\u001b[36m▆\u001b[0m _ _ _ _ _ _ _ _ _ \n",
            "\u001b[36m▆\u001b[0m _ _ _ ▆ _ _ _ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.44\n",
            "----------------------\n",
            "▆ _ _ _ \u001b[36m▆\u001b[0m _ _ _ _ _ \n",
            "▆ _ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ _ _ _ _ \n",
            "▆ _ _ _ \u001b[36m▆\u001b[0m _ _ _ _ _ \n",
            "▆ _ _ _ ▆ _ _ _ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.48\n",
            "----------------------\n",
            "▆ _ _ _ ▆ _ _ _ _ _ \n",
            "▆ _ _ ▆ ▆ _ _ _ _ _ \n",
            "▆ _ _ _ ▆ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ _ \n",
            "▆ _ _ _ ▆ _ \u001b[36m▆\u001b[0m _ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ \u001b[36m▆\u001b[0m ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.52\n",
            "----------------------\n",
            "▆ _ _ _ ▆ _ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ \n",
            "▆ _ _ ▆ ▆ _ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ \n",
            "▆ _ _ _ ▆ _ ▆ ▆ _ _ \n",
            "▆ _ _ _ ▆ _ ▆ _ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.56\n",
            "----------------------\n",
            "_ _ _ _ _ _ _ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m \n",
            "▆ _ _ _ ▆ _ _ ▆ ▆ \u001b[36m▆\u001b[0m \n",
            "▆ _ _ ▆ ▆ _ _ ▆ ▆ \u001b[36m▆\u001b[0m \n",
            "▆ _ _ _ ▆ _ ▆ ▆ _ _ \n",
            "▆ _ _ _ ▆ _ ▆ _ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.5454545454545454\n",
            "----------------------\n",
            "_ _ _ _ _ _ _ _ ▆ ▆ \n",
            "▆ \u001b[36m▆\u001b[0m _ _ ▆ _ _ ▆ ▆ ▆ \n",
            "▆ \u001b[36m▆\u001b[0m _ ▆ ▆ _ _ ▆ ▆ ▆ \n",
            "▆ \u001b[36m▆\u001b[0m _ _ ▆ _ ▆ ▆ _ _ \n",
            "▆ \u001b[36m▆\u001b[0m _ _ ▆ _ ▆ _ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.5818181818181818\n",
            "----------------------\n",
            "\u001b[36m▆\u001b[0m _ _ _ _ _ _ _ _ _ \n",
            "\u001b[36m▆\u001b[0m _ _ _ _ _ _ _ _ _ \n",
            "\u001b[36m▆\u001b[0m _ _ _ _ _ _ _ _ _ \n",
            "\u001b[36m▆\u001b[0m _ _ _ _ _ _ _ ▆ ▆ \n",
            "▆ ▆ _ _ ▆ _ _ ▆ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ ▆ ▆ \n",
            "▆ ▆ _ _ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ _ ▆ _ ▆ _ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.4857142857142857\n",
            "----------------------\n",
            "▆ _ _ _ _ _ _ _ _ \u001b[36m▆\u001b[0m \n",
            "▆ _ _ _ _ _ _ _ _ \u001b[36m▆\u001b[0m \n",
            "▆ _ _ _ _ _ _ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m \n",
            "▆ _ _ _ _ _ _ _ ▆ ▆ \n",
            "▆ ▆ _ _ ▆ _ _ ▆ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ ▆ ▆ \n",
            "▆ ▆ _ _ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ _ ▆ _ ▆ _ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.5142857142857142\n",
            "----------------------\n",
            "_ _ _ _ _ _ _ _ \u001b[36m▆\u001b[0m _ \n",
            "_ _ _ _ _ _ _ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m \n",
            "_ _ _ _ _ _ _ _ _ \u001b[36m▆\u001b[0m \n",
            "▆ _ _ _ _ _ _ _ _ ▆ \n",
            "▆ _ _ _ _ _ _ _ _ ▆ \n",
            "▆ _ _ _ _ _ _ _ ▆ ▆ \n",
            "▆ _ _ _ _ _ _ _ ▆ ▆ \n",
            "▆ ▆ _ _ ▆ _ _ ▆ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ ▆ ▆ \n",
            "▆ ▆ _ _ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ _ ▆ _ ▆ _ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.4470588235294118\n",
            "----------------------\n",
            "\u001b[36m▆\u001b[0m _ _ _ _ _ _ _ _ _ \n",
            "\u001b[36m▆\u001b[0m _ _ _ _ _ _ _ ▆ _ \n",
            "\u001b[36m▆\u001b[0m _ _ _ _ _ _ _ ▆ ▆ \n",
            "\u001b[36m▆\u001b[0m _ _ _ _ _ _ _ _ ▆ \n",
            "▆ _ _ _ _ _ _ _ _ ▆ \n",
            "▆ _ _ _ _ _ _ _ _ ▆ \n",
            "▆ _ _ _ _ _ _ _ ▆ ▆ \n",
            "▆ _ _ _ _ _ _ _ ▆ ▆ \n",
            "▆ ▆ _ _ ▆ _ _ ▆ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ ▆ ▆ \n",
            "▆ ▆ _ _ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ _ ▆ _ ▆ _ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.4444444444444444\n",
            "----------------------\n",
            "▆ _ _ _ _ _ _ _ _ _ \n",
            "▆ _ _ _ _ _ _ _ ▆ _ \n",
            "▆ _ _ _ _ _ _ _ ▆ ▆ \n",
            "▆ _ _ _ _ _ _ _ _ ▆ \n",
            "▆ _ _ _ _ _ _ _ _ ▆ \n",
            "▆ _ _ _ _ _ _ _ _ ▆ \n",
            "▆ _ _ _ _ _ _ _ ▆ ▆ \n",
            "▆ _ \u001b[36m▆\u001b[0m _ _ _ _ _ ▆ ▆ \n",
            "▆ ▆ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m ▆ _ _ ▆ ▆ ▆ \n",
            "▆ ▆ \u001b[36m▆\u001b[0m ▆ ▆ _ _ ▆ ▆ ▆ \n",
            "▆ ▆ _ _ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ _ ▆ _ ▆ _ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.4666666666666667\n",
            "----------------------\n",
            "▆ _ _ _ _ _ _ _ _ _ \n",
            "▆ _ _ _ _ _ _ _ ▆ _ \n",
            "▆ _ _ _ _ _ _ _ ▆ ▆ \n",
            "▆ _ _ _ _ _ _ _ _ ▆ \n",
            "▆ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ _ _ _ _ _ ▆ \n",
            "▆ _ \u001b[36m▆\u001b[0m _ _ _ _ _ _ ▆ \n",
            "▆ _ \u001b[36m▆\u001b[0m _ _ _ _ _ ▆ ▆ \n",
            "▆ _ ▆ _ _ _ _ _ ▆ ▆ \n",
            "▆ ▆ ▆ ▆ ▆ _ _ ▆ ▆ ▆ \n",
            "▆ ▆ ▆ ▆ ▆ _ _ ▆ ▆ ▆ \n",
            "▆ ▆ _ _ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ _ ▆ _ ▆ _ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.4888888888888889\n",
            "----------------------\n",
            "\u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ _ _ _ _ _ _ _ \n",
            "\u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ _ _ _ _ _ _ _ \n",
            "▆ _ _ _ _ _ _ _ _ _ \n",
            "▆ _ _ _ _ _ _ _ ▆ _ \n",
            "▆ _ _ _ _ _ _ _ ▆ ▆ \n",
            "▆ _ _ _ _ _ _ _ _ ▆ \n",
            "▆ ▆ ▆ _ _ _ _ _ _ ▆ \n",
            "▆ _ ▆ _ _ _ _ _ _ ▆ \n",
            "▆ _ ▆ _ _ _ _ _ ▆ ▆ \n",
            "▆ _ ▆ _ _ _ _ _ ▆ ▆ \n",
            "▆ ▆ ▆ ▆ ▆ _ _ ▆ ▆ ▆ \n",
            "▆ ▆ ▆ ▆ ▆ _ _ ▆ ▆ ▆ \n",
            "▆ ▆ _ _ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ _ ▆ _ ▆ _ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.46\n",
            "----------------------\n",
            "▆ ▆ _ _ _ _ _ _ _ _ \n",
            "▆ ▆ _ _ _ _ _ _ _ _ \n",
            "▆ _ _ _ _ _ _ _ _ _ \n",
            "▆ _ _ _ _ _ _ _ ▆ _ \n",
            "▆ _ _ _ _ _ _ _ ▆ ▆ \n",
            "▆ _ _ _ _ _ _ _ _ ▆ \n",
            "▆ ▆ ▆ _ _ _ _ _ _ ▆ \n",
            "▆ _ ▆ _ _ _ _ _ _ ▆ \n",
            "▆ _ ▆ _ _ _ _ _ ▆ ▆ \n",
            "▆ _ ▆ _ _ _ _ _ ▆ ▆ \n",
            "▆ ▆ ▆ ▆ ▆ \u001b[36m▆\u001b[0m _ ▆ ▆ ▆ \n",
            "▆ ▆ ▆ ▆ ▆ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m ▆ ▆ ▆ \n",
            "▆ ▆ _ _ ▆ \u001b[36m▆\u001b[0m ▆ ▆ _ _ \n",
            "▆ ▆ _ _ ▆ _ ▆ _ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.505\n",
            "----------------------\n",
            "▆ ▆ _ _ _ _ _ _ _ _ \n",
            "▆ ▆ _ _ _ _ _ _ _ _ \n",
            "▆ _ _ _ _ _ _ _ _ _ \n",
            "▆ _ _ _ _ _ _ _ ▆ _ \n",
            "▆ _ _ _ _ _ _ _ ▆ ▆ \n",
            "▆ _ _ _ _ _ _ _ _ ▆ \n",
            "▆ ▆ ▆ _ _ _ _ _ _ ▆ \n",
            "▆ _ ▆ _ _ _ \u001b[36m▆\u001b[0m _ _ ▆ \n",
            "▆ _ ▆ _ _ _ \u001b[36m▆\u001b[0m _ ▆ ▆ \n",
            "▆ _ ▆ _ _ _ \u001b[36m▆\u001b[0m _ ▆ ▆ \n",
            "▆ ▆ ▆ ▆ ▆ ▆ \u001b[36m▆\u001b[0m ▆ ▆ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ _ \n",
            "▆ ▆ _ _ ▆ _ ▆ _ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.5\n",
            "----------------------\n",
            "▆ ▆ _ _ _ _ _ _ _ _ \n",
            "▆ ▆ _ _ _ _ _ _ _ _ \n",
            "▆ _ _ _ _ _ _ _ _ _ \n",
            "▆ _ _ _ _ _ _ _ ▆ _ \n",
            "▆ _ _ _ _ \u001b[36m▆\u001b[0m _ _ ▆ ▆ \n",
            "▆ _ _ _ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ _ ▆ \n",
            "▆ ▆ ▆ _ _ _ \u001b[36m▆\u001b[0m _ _ ▆ \n",
            "▆ _ ▆ _ _ _ ▆ _ _ ▆ \n",
            "▆ _ ▆ _ _ _ ▆ _ ▆ ▆ \n",
            "▆ _ ▆ _ _ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ _ \n",
            "▆ ▆ _ _ ▆ _ ▆ _ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.4666666666666667\n",
            "----------------------\n",
            "▆ ▆ _ _ _ _ _ _ _ _ \n",
            "▆ ▆ _ _ _ _ _ _ _ _ \n",
            "▆ _ _ _ _ _ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ \n",
            "▆ _ _ _ _ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m ▆ _ \n",
            "▆ _ _ _ _ ▆ _ _ ▆ ▆ \n",
            "▆ _ _ _ _ ▆ ▆ _ _ ▆ \n",
            "▆ ▆ ▆ _ _ _ ▆ _ _ ▆ \n",
            "▆ _ ▆ _ _ _ ▆ _ _ ▆ \n",
            "▆ _ ▆ _ _ _ ▆ _ ▆ ▆ \n",
            "▆ _ ▆ _ _ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ _ \n",
            "▆ ▆ _ _ ▆ _ ▆ _ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.4888888888888889\n",
            "----------------------\n",
            "▆ ▆ _ _ _ _ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ \n",
            "▆ ▆ _ _ _ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ _ \n",
            "▆ _ _ _ _ _ _ ▆ ▆ _ \n",
            "▆ _ _ _ _ _ ▆ ▆ ▆ _ \n",
            "▆ _ _ _ _ ▆ _ _ ▆ ▆ \n",
            "▆ _ _ _ _ ▆ ▆ _ _ ▆ \n",
            "▆ ▆ ▆ _ _ _ ▆ _ _ ▆ \n",
            "▆ _ ▆ _ _ _ ▆ _ _ ▆ \n",
            "▆ _ ▆ _ _ _ ▆ _ ▆ ▆ \n",
            "▆ _ ▆ _ _ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ _ \n",
            "▆ ▆ _ _ ▆ _ ▆ _ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.5111111111111111\n",
            "----------------------\n",
            "▆ ▆ _ _ _ _ _ ▆ ▆ _ \n",
            "▆ ▆ _ _ _ _ ▆ ▆ _ _ \n",
            "▆ _ _ _ _ _ _ ▆ ▆ _ \n",
            "▆ _ _ _ _ _ ▆ ▆ ▆ _ \n",
            "▆ _ _ _ _ ▆ _ _ ▆ ▆ \n",
            "▆ _ _ _ _ ▆ ▆ _ _ ▆ \n",
            "▆ ▆ ▆ _ _ _ ▆ _ _ ▆ \n",
            "▆ _ ▆ _ _ _ ▆ _ _ ▆ \n",
            "▆ _ ▆ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ ▆ _ ▆ ▆ \n",
            "▆ _ ▆ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ _ \n",
            "▆ ▆ _ _ ▆ _ ▆ _ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.5333333333333333\n",
            "----------------------\n",
            "▆ ▆ _ _ _ _ _ ▆ ▆ _ \n",
            "▆ ▆ _ _ _ _ ▆ ▆ _ _ \n",
            "▆ _ _ _ _ _ _ ▆ ▆ _ \n",
            "▆ _ _ _ _ _ ▆ ▆ ▆ _ \n",
            "▆ _ _ _ _ ▆ _ _ ▆ ▆ \n",
            "▆ _ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m ▆ ▆ _ _ ▆ \n",
            "▆ ▆ ▆ _ \u001b[36m▆\u001b[0m _ ▆ _ _ ▆ \n",
            "▆ _ ▆ _ \u001b[36m▆\u001b[0m _ ▆ _ _ ▆ \n",
            "▆ _ ▆ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ _ ▆ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ _ \n",
            "▆ ▆ _ _ ▆ _ ▆ _ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.5555555555555556\n",
            "----------------------\n",
            "▆ ▆ _ _ _ _ _ ▆ ▆ _ \n",
            "▆ ▆ _ _ _ _ ▆ ▆ _ _ \n",
            "▆ _ _ \u001b[36m▆\u001b[0m _ _ _ ▆ ▆ _ \n",
            "▆ _ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ ▆ ▆ ▆ _ \n",
            "▆ _ _ \u001b[36m▆\u001b[0m _ ▆ _ _ ▆ ▆ \n",
            "▆ _ _ ▆ ▆ ▆ ▆ _ _ ▆ \n",
            "▆ ▆ ▆ _ ▆ _ ▆ _ _ ▆ \n",
            "▆ _ ▆ _ ▆ _ ▆ _ _ ▆ \n",
            "▆ _ ▆ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ _ ▆ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ _ \n",
            "▆ ▆ _ _ ▆ _ ▆ _ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.5777777777777777\n",
            "----------------------\n",
            "▆ ▆ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ _ ▆ ▆ _ \n",
            "▆ ▆ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ ▆ ▆ _ _ \n",
            "▆ _ _ ▆ _ _ _ ▆ ▆ _ \n",
            "▆ _ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ _ _ ▆ _ ▆ _ _ ▆ ▆ \n",
            "▆ _ _ ▆ ▆ ▆ ▆ _ _ ▆ \n",
            "▆ ▆ ▆ _ ▆ _ ▆ _ _ ▆ \n",
            "▆ _ ▆ _ ▆ _ ▆ _ _ ▆ \n",
            "▆ _ ▆ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ _ ▆ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ _ \n",
            "▆ ▆ _ _ ▆ _ ▆ _ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.6\n",
            "----------------------\n",
            "_ _ _ _ \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m \u001b[36m▆\u001b[0m _ _ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ _ _ ▆ _ _ _ ▆ ▆ _ \n",
            "▆ _ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ _ _ ▆ _ ▆ _ _ ▆ ▆ \n",
            "▆ _ _ ▆ ▆ ▆ ▆ _ _ ▆ \n",
            "▆ ▆ ▆ _ ▆ _ ▆ _ _ ▆ \n",
            "▆ _ ▆ _ ▆ _ ▆ _ _ ▆ \n",
            "▆ _ ▆ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ _ ▆ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ _ \n",
            "▆ ▆ _ _ ▆ _ ▆ _ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ _ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ ▆ ▆ _ \n",
            "▆ ▆ _ ▆ ▆ _ ▆ _ ▆ ▆ \n",
            "▆ ▆ _ ▆ ▆ _ _ ▆ _ ▆ \n",
            "▆ ▆ _ _ ▆ ▆ ▆ ▆ _ ▆ \n",
            "Reward: 0.5894736842105263\n",
            "----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def render_alt(board, pattern, bl_coords, color=True):\n",
        "    board = board.copy()\n",
        "\n",
        "    # Highlight tiles where the last piece was played\n",
        "    lrow, lcol = bl_coords\n",
        "\n",
        "    print(bl_coords)\n",
        "\n",
        "    p_height = len(pattern)\n",
        "    output = False\n",
        "\n",
        "    for r in range(p_height):\n",
        "        pattern_row = pattern[len(pattern)-1-r]\n",
        "        board_row = board[lrow-1+r]\n",
        "\n",
        "        print(pattern_row)\n",
        "        print(f\"Row: {lrow-1+r}, {board_row}\")\n",
        "\n",
        "        for i, c in enumerate(pattern_row):\n",
        "            # Iff c is 1, push it to the board\n",
        "            if c == 1:\n",
        "                board_row[lcol-1+i] = 2\n",
        "\n",
        "\n",
        "    for i, row in enumerate(reversed(board)):\n",
        "        if sum(row) == 0 and not output:\n",
        "            continue\n",
        "        else:\n",
        "            output = True\n",
        "\n",
        "        for cell in row:\n",
        "            if cell == 2:\n",
        "                print(f\"\\033[36m{TetrisBoard.BLOCK}\\033[0m\", end=' ')\n",
        "            elif cell == 1:\n",
        "                print(TetrisBoard.BLOCK, end=' ')\n",
        "            else:\n",
        "                print('_', end=' ')\n",
        "        print()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(game0.moves):\n",
        "    board = game0.boards[i]\n",
        "    piece = game0.pieces[i]\n",
        "    placement = game0.placements[i]\n",
        "\n",
        "    if piece and placement:\n",
        "        render_alt(game0.boards[i], game0.pieces[i]['pattern'], game0.placements[i])\n",
        "        print(\"----------------------\")"
      ],
      "metadata": {
        "id": "nri8zzAe7VTa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}